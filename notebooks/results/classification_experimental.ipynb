{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Classification on experimental data\n",
    "This notebook is the primary source of plots and tables for the classificationn part of the thesis, \n",
    "with the goal of keeping every table and figure as standardized as possible. \n",
    "## Questions\n",
    "* Descriptive statistics\n",
    "    - Should descriptive statistics of the simulated data be included?\\\n",
    "    If so, how much? And should it be included for each fold in the k-fold cross-validation?\n",
    "* Classification results\n",
    "    - Breakdown of results based on event type? Single, double, close double?\n",
    "    Reasonable to include in order to confirm the assumption that close doubles are the\n",
    "    most difficult event type to classify correctly in simulated data\n",
    "    Random state is included, so should be simple to reproduce the indices\n",
    "\n",
    "\n",
    "## Handy links\n",
    "* [matplotlib-plots to latex](https://timodenk.com/blog/exporting-matplotlib-plots-to-latex/)\n",
    "* [Robert's thesis df output](https://github.com/ATTPC/VAE-event-classification/blob/master/src/make_classification_table.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from master_scripts.data_functions import *\n",
    "from master_scripts.analysis_functions import *\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "THESIS_PATH = \"../../../master_thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental set and normalize\n",
    "repo_root = get_git_root()\n",
    "events, images_real = import_real_data(repo_root + \"data/real/anodedata_500k.txt\") # images not normalized\n",
    "\n",
    "# normalize each event type separately\n",
    "descriptors = list(set([event['event_descriptor'] for event in events.values()]))\n",
    "image_indices = {}\n",
    "for d in descriptors:\n",
    "    img_idx = np.array([event['image_idx'] for event in events.values() if event['event_descriptor'] == d])\n",
    "    # append labeled doubles to decays for normalization.\n",
    "    if d == 16:\n",
    "        image_indices[2] = np.concatenate((image_indices[2], img_idx), axis=0)\n",
    "    else:\n",
    "        image_indices[d] = img_idx\n",
    "for indices in image_indices.values():\n",
    "    images_real[indices] = normalize_image_data(images_real[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES FOR PLOT\n",
    "HIST_DICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model, images, events, threshold=0.5):\n",
    "    # Get prediction and make class labels based on threshold of 0.5\n",
    "    y_out = model.predict(images)\n",
    "    y_pred = (y_out > threshold).astype(int)\n",
    "    for event_id in events.keys():\n",
    "        if y_pred[events[event_id]['image_idx']] == 0:\n",
    "            events[event_id]['event_class'] = \"single\"\n",
    "        else:\n",
    "            events[event_id]['event_class'] = \"double\"\n",
    "\n",
    "    return events\n",
    "\n",
    "def classification_metrics(model, images, events, name, threshold=0.5):\n",
    "    # Get prediction and make class labels based on threshold of 0.5\n",
    "    y_out = model.predict(images)\n",
    "    y_pred = (y_out > threshold).astype(int)\n",
    "    for event_id in events.keys():\n",
    "        if y_pred[events[event_id]['image_idx']] == 0:\n",
    "            events[event_id]['event_class'] = \"single\"\n",
    "        else:\n",
    "            events[event_id]['event_class'] = \"double\"\n",
    "            \n",
    "    descriptors = list(set([event['event_descriptor'] for event in events.values()]))\n",
    "    \n",
    "    desc_class = {'single': [], 'double': []}\n",
    "    for event in events.values():\n",
    "        desc_class[event['event_class']].append(event['event_descriptor'])\n",
    "    \n",
    "    translate_descriptor = {\n",
    "        1: \"Implant\",\n",
    "        2: \"Decay\",\n",
    "        3: \"implant + Decay\",\n",
    "        4: \"Light ion\",\n",
    "        5: \"Implant + Light Ion\",\n",
    "        6: \"Decay + Light Ion\",\n",
    "        7: \"Implant + Decay + Light Ion\",\n",
    "        8: \"Double (time)\",\n",
    "        9: \"Implant + Double (time)\",\n",
    "        10: \"Decay + Double (time)\",\n",
    "        11: \"Implant + Decay + Double (time)\",\n",
    "        12: \"Light ion + Double (time)\",\n",
    "        13: \"Implant + Light Ion + Double (time)\",\n",
    "        14: \"Decay + Light ion + Double (time)\",\n",
    "        15: \"Implant + Decay + Light Ion + Double (time)\",\n",
    "        16: \"Double (space)\",\n",
    "        17: \"Implant + Double (space)\",\n",
    "        18: \"Decay + Double (space)\"\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for d in descriptors:\n",
    "        num_s = desc_class['single'].count(d)\n",
    "        num_d = desc_class['double'].count(d)\n",
    "        tot = num_s + num_d\n",
    "        norm_s = num_s / tot\n",
    "        norm_d = num_d / tot\n",
    "        results[translate_descriptor[d]] = [\n",
    "            num_s,\n",
    "            num_d,\n",
    "            norm_s,\n",
    "            norm_d\n",
    "        ]\n",
    "    \n",
    "    cols = [\"Predicted single\", \"Predicted double\", \"Normalized single\", \"Normalized double\"]\n",
    "    df = pd.DataFrame.from_dict(data=results, orient='index', columns=cols)\n",
    "    \n",
    "    # histogram dict addition\n",
    "    decays = [e['image_idx'] for e in events.values() if e['event_descriptor'] == 2]\n",
    "    single = (y_out[decays] <= 0.5).reshape(len(decays))\n",
    "    double = y_out[decays] > 0.5\n",
    "    img_sum = np.sum(images_real[decays], axis=(1,2)).reshape(len(decays))\n",
    "    pixel_sums = np.linspace(0, 20, 50)\n",
    "    counts, bins = np.histogram(img_sum[single], bins=pixel_sums)\n",
    "    name = name + \"_i\"\n",
    "    if name in HIST_DICT:\n",
    "        if name + \"i\" in HIST_DICT:\n",
    "            HIST_DICT[name + \"ii\"] = [bins, counts]\n",
    "        else:\n",
    "            HIST_DICT[name + \"i\"] = [bins, counts]\n",
    "    else:\n",
    "        HIST_DICT[name] = [bins, counts]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment id's\n",
    "experiments_nomod = {\n",
    "    'logistic': \"1bc7c249cd14\",\n",
    "    'dense': \"301dfb138506\",\n",
    "    'cnn': \"7f2dd7f1d24c\",\n",
    "    'pretrained': \"94685622cb2d\",\n",
    "    'custom': \"e8772df34916\",\n",
    "}\n",
    "experiments_pixelmod = {\n",
    "    'logistic': \"292d34a807ea\",\n",
    "    'dense': \"48203947802a\",\n",
    "    'cnn': \"35afebe71164\",\n",
    "    'pretrained': \"6aebbcd131d1\",\n",
    "    'custom': \"05b90ffdfc3c\",\n",
    "}\n",
    "experiments_imbalanced = {\n",
    "    'logistic': \"9380b00c72f5\",\n",
    "    'dense': \"851d3c6f60c8\",\n",
    "    'cnn': \"d34250436c72\",\n",
    "    'pretrained': \"dd1df8beb788\",\n",
    "    'custom': \"28fd163fc0c1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed simulated data - no additional modifications\n",
    "This is the basic metrics for all the models trained on simulated data.\n",
    "The basic pre-processing includes formatting and min-max normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "log_ex_id = experiments_nomod['logistic']\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "\n",
    "# Load model and predict\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "log_test = classification_metrics(log_model, images_real.reshape(images_real.shape[0], 256), events, \"log_test\")\n",
    "del log_model #No longer needed, clear memory just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "dense_ex_id = experiments_nomod['dense']\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "dense_test = classification_metrics(dense_model, images_real.reshape(images_real.shape[0], 256), events, \"dense_test\")\n",
    "del dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "cnn_ex_id = experiments_nomod['cnn']\n",
    "cnn_ex = load_experiment(cnn_ex_id)\n",
    "cnn_model = tf.keras.models.load_model(repo_root + \"models/\" + cnn_ex_id + \".h5\", compile=False)\n",
    "cnn_test = classification_metrics(cnn_model, images_real, events, \"cnn_test\")\n",
    "del cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained - VGG\n",
    "As an additional baseline for performance, we include a pretrained SOTA network\n",
    "where trained on the ImageNet database.\n",
    "\n",
    "Due to the size of our detector images (16x16) compared with the size the VGG network is\n",
    "designed for, we cannot use all layers in the VGG network. This stems from the use of max-pooling\n",
    "which effectively reduces the image size to half (8x8) each time the input is passed through such a\n",
    "layer. At some point our input is too small to pass through to the rest of the network.\n",
    "We therefore cut the network at the point where this becomes and issue.\n",
    "Alternatively, one could possibly keep the depth but remove max-pooling layers.\n",
    "\n",
    "\n",
    "It is common in transfer learning to use a pretrained model which is then fine-tuned on task-specific data.\n",
    "You can then view the pretraining as a step to get a \"good\" initialization for weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained regression experiment\n",
    "pretrained_ex_id = experiments_nomod['pretrained']\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "pretrained_test = classification_metrics(pretrained_model, np.concatenate((images_real, images_real, images_real), axis=-1), events, \"pretrained_test\")\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom classification experiment\n",
    "custom_ex_id = experiments_nomod['custom']\n",
    "custom_ex = load_experiment(custom_ex_id)\n",
    "custom_model = tf.keras.models.load_model(repo_root + \"models/\" + custom_ex_id + \".h5\", compile=False)\n",
    "custom_test = classification_metrics(custom_model, images_real, events, \"custom_test\")\n",
    "predictions = custom_model.predict(normalize_image_data(images_real))\n",
    "del custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the metrics into one table\n",
    "We use the standard deviation in the folds as an error measure, and report the mean classification f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>95565.0</td>\n",
       "      <td>164582.0</td>\n",
       "      <td>0.367350</td>\n",
       "      <td>0.632650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>92920.0</td>\n",
       "      <td>167227.0</td>\n",
       "      <td>0.357183</td>\n",
       "      <td>0.642817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>62359.0</td>\n",
       "      <td>197788.0</td>\n",
       "      <td>0.239707</td>\n",
       "      <td>0.760293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>53837.0</td>\n",
       "      <td>206310.0</td>\n",
       "      <td>0.206948</td>\n",
       "      <td>0.793052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>20219.0</td>\n",
       "      <td>239928.0</td>\n",
       "      <td>0.077721</td>\n",
       "      <td>0.922279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    95565.0           164582.0          0.367350            \n",
       "Dense       92920.0           167227.0          0.357183            \n",
       "CNN         62359.0           197788.0          0.239707            \n",
       "Pretrained  53837.0           206310.0          0.206948            \n",
       "Custom      20219.0           239928.0          0.077721            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.632650           \n",
       "Dense       0.642817           \n",
       "CNN         0.760293           \n",
       "Pretrained  0.793052           \n",
       "Custom      0.922279           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    0.0               17.0              0.0                 \n",
       "Dense       0.0               17.0              0.0                 \n",
       "CNN         17.0              0.0               1.0                 \n",
       "Pretrained  0.0               17.0              0.0                 \n",
       "Custom      0.0               17.0              0.0                 \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    1.0                \n",
       "Dense       1.0                \n",
       "CNN         0.0                \n",
       "Pretrained  1.0                \n",
       "Custom      1.0                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_decays = pd.DataFrame.from_dict(\n",
    "    data={\n",
    "        'Logistic': log_test.iloc[1],\n",
    "        'Dense': dense_test.iloc[1],\n",
    "        'CNN': cnn_test.iloc[1],\n",
    "        'Pretrained': pretrained_test.iloc[1],\n",
    "        'Custom': custom_test.iloc[1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "all_labeled_doubles = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "        'Logistic': log_test.iloc[-1],\n",
    "        'Dense': dense_test.iloc[-1],\n",
    "        'CNN': cnn_test.iloc[-1],\n",
    "        'Pretrained': pretrained_test.iloc[-1],\n",
    "        'Custom': custom_test.iloc[-1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "display(all_decays)\n",
    "display(all_labeled_doubles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed simulated data - Pixel modified\n",
    "The basic pre-processing includes formatting and min-max normalization.\n",
    "Additionally, the data has had the top and bottom lines of pixels set to 0, plus\n",
    "one pixel inside the detector permanently 0 (which idx again?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "log_ex_id = experiments_pixelmod['logistic']\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "\n",
    "# Load model\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "log_test_pmod = classification_metrics(log_model, images_real.reshape(images_real.shape[0], 256), events, \"log_test\")\n",
    "del log_model #No longer needed, clear memory just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "dense_ex_id = experiments_pixelmod['dense']\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "dense_test_pmod = classification_metrics(dense_model, images_real.reshape(images_real.shape[0], 256), events, \"dense_test\")\n",
    "del dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "cnn_ex_id = experiments_pixelmod['cnn']\n",
    "cnn_ex = load_experiment(cnn_ex_id)\n",
    "cnn_model = tf.keras.models.load_model(repo_root + \"models/\" + cnn_ex_id + \".h5\", compile=False)\n",
    "cnn_test_pmod = classification_metrics(cnn_model, images_real, events, \"cnn_test\")\n",
    "del cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained - VGG\n",
    "As an additional baseline for performance, we include a pretrained SOTA network\n",
    "where trained on the ImageNet database.\n",
    "\n",
    "Due to the size of our detector images (16x16) compared with the size the VGG network is\n",
    "designed for, we cannot use all layers in the VGG network. This stems from the use of max-pooling\n",
    "which effectively reduces the image size to half (8x8) each time the input is passed through such a\n",
    "layer. At some point our input is too small to pass through to the rest of the network.\n",
    "We therefore cut the network at the point where this becomes and issue.\n",
    "Alternatively, one could possibly keep the depth but remove max-pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "pretrained_ex_id = experiments_pixelmod['pretrained']\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "pretrained_test_pmod = classification_metrics(pretrained_model, np.concatenate((images_real, images_real, images_real), axis=-1), events, \"pretrained_test\")\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom classification experiment\n",
    "custom_ex_id = experiments_pixelmod['custom']\n",
    "custom_ex = load_experiment(custom_ex_id)\n",
    "custom_model = tf.keras.models.load_model(repo_root + \"models/\" + custom_ex_id + \".h5\", compile=False)\n",
    "custom_test_pmod = classification_metrics(custom_model, images_real, events, \"custom_test\")\n",
    "del custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the metrics into one table\n",
    "We use the standard deviation in the folds as an error measure, and report the mean classification f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>97629.0</td>\n",
       "      <td>162518.0</td>\n",
       "      <td>0.375284</td>\n",
       "      <td>0.624716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>97498.0</td>\n",
       "      <td>162649.0</td>\n",
       "      <td>0.374780</td>\n",
       "      <td>0.625220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>55512.0</td>\n",
       "      <td>204635.0</td>\n",
       "      <td>0.213387</td>\n",
       "      <td>0.786613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>48449.0</td>\n",
       "      <td>211698.0</td>\n",
       "      <td>0.186237</td>\n",
       "      <td>0.813763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>17859.0</td>\n",
       "      <td>242288.0</td>\n",
       "      <td>0.068650</td>\n",
       "      <td>0.931350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    97629.0           162518.0          0.375284            \n",
       "Dense       97498.0           162649.0          0.374780            \n",
       "CNN         55512.0           204635.0          0.213387            \n",
       "Pretrained  48449.0           211698.0          0.186237            \n",
       "Custom      17859.0           242288.0          0.068650            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.624716           \n",
       "Dense       0.625220           \n",
       "CNN         0.786613           \n",
       "Pretrained  0.813763           \n",
       "Custom      0.931350           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    0.0               17.0              0.0                 \n",
       "Dense       0.0               17.0              0.0                 \n",
       "CNN         0.0               17.0              0.0                 \n",
       "Pretrained  0.0               17.0              0.0                 \n",
       "Custom      0.0               17.0              0.0                 \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    1.0                \n",
       "Dense       1.0                \n",
       "CNN         1.0                \n",
       "Pretrained  1.0                \n",
       "Custom      1.0                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_decays_pmod = pd.DataFrame.from_dict(\n",
    "    data={\n",
    "        'Logistic': log_test_pmod.iloc[1],\n",
    "        'Dense': dense_test_pmod.iloc[1],\n",
    "        'CNN': cnn_test_pmod.iloc[1],\n",
    "        'Pretrained': pretrained_test_pmod.iloc[1],\n",
    "        'Custom': custom_test_pmod.iloc[1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "all_labeled_doubles_pmod = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "        'Logistic': log_test_pmod.iloc[-1],\n",
    "        'Dense': dense_test_pmod.iloc[-1],\n",
    "        'CNN': cnn_test_pmod.iloc[-1],\n",
    "        'Pretrained': pretrained_test_pmod.iloc[-1],\n",
    "        'Custom': custom_test_pmod.iloc[-1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "display(all_decays_pmod)\n",
    "display(all_labeled_doubles_pmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed simulated data - Pixel modified and imbalanced\n",
    "The basic pre-processing includes formatting and min-max normalization.\n",
    "Additionally, the data has had the top and bottom lines of pixels set to 0, plus\n",
    "one pixel inside the detector permanently 0 (which idx again?).\n",
    "\n",
    "This dataset has also been purposefully imbalanced to mimic the properties of experimental data\n",
    "where doubles in space are expected to be rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "log_ex_id = experiments_imbalanced['logistic']\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "\n",
    "# Load model\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "log_test_imbalanced = classification_metrics(log_model, images_real.reshape(images_real.shape[0], 256), events, \"log_test\")\n",
    "del log_model #No longer needed, clear memory just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "dense_ex_id = experiments_imbalanced['dense']\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "dense_test_imbalanced = classification_metrics(dense_model, images_real.reshape(images_real.shape[0], 256), events, \"dense_test\")\n",
    "del dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "cnn_ex_id = experiments_imbalanced['cnn']\n",
    "cnn_ex = load_experiment(cnn_ex_id)\n",
    "cnn_model = tf.keras.models.load_model(repo_root + \"models/\" + cnn_ex_id + \".h5\", compile=False)\n",
    "cnn_test_imbalanced = classification_metrics(cnn_model, images_real, events, \"cnn_test\")\n",
    "del cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained - VGG\n",
    "As an additional baseline for performance, we include a pretrained SOTA network\n",
    "where trained on the ImageNet database.\n",
    "\n",
    "Due to the size of our detector images (16x16) compared with the size the VGG network is\n",
    "designed for, we cannot use all layers in the VGG network. This stems from the use of max-pooling\n",
    "which effectively reduces the image size to half (8x8) each time the input is passed through such a\n",
    "layer. At some point our input is too small to pass through to the rest of the network.\n",
    "We therefore cut the network at the point where this becomes and issue.\n",
    "Alternatively, one could possibly keep the depth but remove max-pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "pretrained_ex_id = experiments_imbalanced['pretrained']\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "pretrained_test_imbalanced = classification_metrics(pretrained_model, np.concatenate((images_real, images_real, images_real), axis=-1), events, \"pretrained_test\")\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom classification experiment\n",
    "custom_ex_id = experiments_imbalanced['custom']\n",
    "custom_ex = load_experiment(custom_ex_id)\n",
    "custom_model = tf.keras.models.load_model(repo_root + \"models/\" + custom_ex_id + \".h5\", compile=False)\n",
    "custom_test_imbalanced = classification_metrics(custom_model, images_real, events, \"custom_test\")\n",
    "del custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the metrics into one table\n",
    "We use the standard deviation in the folds as an error measure, and report the mean classification f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>139578.0</td>\n",
       "      <td>120569.0</td>\n",
       "      <td>0.536535</td>\n",
       "      <td>0.463465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>139405.0</td>\n",
       "      <td>120742.0</td>\n",
       "      <td>0.535870</td>\n",
       "      <td>0.464130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>58870.0</td>\n",
       "      <td>201277.0</td>\n",
       "      <td>0.226295</td>\n",
       "      <td>0.773705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>58534.0</td>\n",
       "      <td>201613.0</td>\n",
       "      <td>0.225004</td>\n",
       "      <td>0.774996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>29441.0</td>\n",
       "      <td>230706.0</td>\n",
       "      <td>0.113171</td>\n",
       "      <td>0.886829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    139578.0          120569.0          0.536535            \n",
       "Dense       139405.0          120742.0          0.535870            \n",
       "CNN         58870.0           201277.0          0.226295            \n",
       "Pretrained  58534.0           201613.0          0.225004            \n",
       "Custom      29441.0           230706.0          0.113171            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.463465           \n",
       "Dense       0.464130           \n",
       "CNN         0.773705           \n",
       "Pretrained  0.774996           \n",
       "Custom      0.886829           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    0.0               17.0              0.000000            \n",
       "Dense       0.0               17.0              0.000000            \n",
       "CNN         4.0               13.0              0.235294            \n",
       "Pretrained  0.0               17.0              0.000000            \n",
       "Custom      0.0               17.0              0.000000            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    1.000000           \n",
       "Dense       1.000000           \n",
       "CNN         0.764706           \n",
       "Pretrained  1.000000           \n",
       "Custom      1.000000           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_decays_imbalanced = pd.DataFrame.from_dict(\n",
    "    data={\n",
    "        'Logistic': log_test_imbalanced.iloc[1],\n",
    "        'Dense': dense_test_imbalanced.iloc[1],\n",
    "        'CNN': cnn_test_imbalanced.iloc[1],\n",
    "        'Pretrained': pretrained_test_imbalanced.iloc[1],\n",
    "        'Custom': custom_test_imbalanced.iloc[1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "all_labeled_doubles_imbalanced = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "        'Logistic': log_test_imbalanced.iloc[-1],\n",
    "        'Dense': dense_test_imbalanced.iloc[-1],\n",
    "        'CNN': cnn_test_imbalanced.iloc[-1],\n",
    "        'Pretrained': pretrained_test_imbalanced.iloc[-1],\n",
    "        'Custom': custom_test_imbalanced.iloc[-1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "display(all_decays_imbalanced)\n",
    "display(all_labeled_doubles_imbalanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single (a)</th>\n",
       "      <th>Double (a)</th>\n",
       "      <th>Single (b)</th>\n",
       "      <th>Double (b)</th>\n",
       "      <th>Single (c)</th>\n",
       "      <th>Double (c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>$\\underset{\\num{ 95565 }  }{\\num{ 0.367 } }$</td>\n",
       "      <td>$\\underset{\\num{ 164582 }  }{\\num{ 0.633 } }$</td>\n",
       "      <td>$\\underset{\\num{ 97629 }  }{\\num{ 0.375 } }$</td>\n",
       "      <td>$\\underset{\\num{ 162518 }  }{\\num{ 0.625 } }$</td>\n",
       "      <td>$\\underset{\\num{ 139578 }  }{\\num{ 0.537 } }$</td>\n",
       "      <td>$\\underset{\\num{ 120569 }  }{\\num{ 0.463 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>$\\underset{\\num{ 92920 }  }{\\num{ 0.357 } }$</td>\n",
       "      <td>$\\underset{\\num{ 167227 }  }{\\num{ 0.643 } }$</td>\n",
       "      <td>$\\underset{\\num{ 97498 }  }{\\num{ 0.375 } }$</td>\n",
       "      <td>$\\underset{\\num{ 162649 }  }{\\num{ 0.625 } }$</td>\n",
       "      <td>$\\underset{\\num{ 139405 }  }{\\num{ 0.536 } }$</td>\n",
       "      <td>$\\underset{\\num{ 120742 }  }{\\num{ 0.464 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>$\\underset{\\num{ 62359 }  }{\\num{ 0.240 } }$</td>\n",
       "      <td>$\\underset{\\num{ 197788 }  }{\\num{ 0.760 } }$</td>\n",
       "      <td>$\\underset{\\num{ 55512 }  }{\\num{ 0.213 } }$</td>\n",
       "      <td>$\\underset{\\num{ 204635 }  }{\\num{ 0.787 } }$</td>\n",
       "      <td>$\\underset{\\num{ 58870 }  }{\\num{ 0.226 } }$</td>\n",
       "      <td>$\\underset{\\num{ 201277 }  }{\\num{ 0.774 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>$\\underset{\\num{ 53837 }  }{\\num{ 0.207 } }$</td>\n",
       "      <td>$\\underset{\\num{ 206310 }  }{\\num{ 0.793 } }$</td>\n",
       "      <td>$\\underset{\\num{ 48449 }  }{\\num{ 0.186 } }$</td>\n",
       "      <td>$\\underset{\\num{ 211698 }  }{\\num{ 0.814 } }$</td>\n",
       "      <td>$\\underset{\\num{ 58534 }  }{\\num{ 0.225 } }$</td>\n",
       "      <td>$\\underset{\\num{ 201613 }  }{\\num{ 0.775 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>$\\underset{\\num{ 20219 }  }{\\num{ 0.078 } }$</td>\n",
       "      <td>$\\underset{\\num{ 239928 }  }{\\num{ 0.922 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17859 }  }{\\num{ 0.069 } }$</td>\n",
       "      <td>$\\underset{\\num{ 242288 }  }{\\num{ 0.931 } }$</td>\n",
       "      <td>$\\underset{\\num{ 29441 }  }{\\num{ 0.113 } }$</td>\n",
       "      <td>$\\underset{\\num{ 230706 }  }{\\num{ 0.887 } }$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Single (a)  \\\n",
       "Logistic    $\\underset{\\num{ 95565 }  }{\\num{ 0.367 } }$   \n",
       "Dense       $\\underset{\\num{ 92920 }  }{\\num{ 0.357 } }$   \n",
       "CNN         $\\underset{\\num{ 62359 }  }{\\num{ 0.240 } }$   \n",
       "Pretrained  $\\underset{\\num{ 53837 }  }{\\num{ 0.207 } }$   \n",
       "Custom      $\\underset{\\num{ 20219 }  }{\\num{ 0.078 } }$   \n",
       "\n",
       "                                               Double (a)  \\\n",
       "Logistic    $\\underset{\\num{ 164582 }  }{\\num{ 0.633 } }$   \n",
       "Dense       $\\underset{\\num{ 167227 }  }{\\num{ 0.643 } }$   \n",
       "CNN         $\\underset{\\num{ 197788 }  }{\\num{ 0.760 } }$   \n",
       "Pretrained  $\\underset{\\num{ 206310 }  }{\\num{ 0.793 } }$   \n",
       "Custom      $\\underset{\\num{ 239928 }  }{\\num{ 0.922 } }$   \n",
       "\n",
       "                                              Single (b)  \\\n",
       "Logistic    $\\underset{\\num{ 97629 }  }{\\num{ 0.375 } }$   \n",
       "Dense       $\\underset{\\num{ 97498 }  }{\\num{ 0.375 } }$   \n",
       "CNN         $\\underset{\\num{ 55512 }  }{\\num{ 0.213 } }$   \n",
       "Pretrained  $\\underset{\\num{ 48449 }  }{\\num{ 0.186 } }$   \n",
       "Custom      $\\underset{\\num{ 17859 }  }{\\num{ 0.069 } }$   \n",
       "\n",
       "                                               Double (b)  \\\n",
       "Logistic    $\\underset{\\num{ 162518 }  }{\\num{ 0.625 } }$   \n",
       "Dense       $\\underset{\\num{ 162649 }  }{\\num{ 0.625 } }$   \n",
       "CNN         $\\underset{\\num{ 204635 }  }{\\num{ 0.787 } }$   \n",
       "Pretrained  $\\underset{\\num{ 211698 }  }{\\num{ 0.814 } }$   \n",
       "Custom      $\\underset{\\num{ 242288 }  }{\\num{ 0.931 } }$   \n",
       "\n",
       "                                               Single (c)  \\\n",
       "Logistic    $\\underset{\\num{ 139578 }  }{\\num{ 0.537 } }$   \n",
       "Dense       $\\underset{\\num{ 139405 }  }{\\num{ 0.536 } }$   \n",
       "CNN         $\\underset{\\num{ 58870 }  }{\\num{ 0.226 } }$    \n",
       "Pretrained  $\\underset{\\num{ 58534 }  }{\\num{ 0.225 } }$    \n",
       "Custom      $\\underset{\\num{ 29441 }  }{\\num{ 0.113 } }$    \n",
       "\n",
       "                                               Double (c)  \n",
       "Logistic    $\\underset{\\num{ 120569 }  }{\\num{ 0.463 } }$  \n",
       "Dense       $\\underset{\\num{ 120742 }  }{\\num{ 0.464 } }$  \n",
       "CNN         $\\underset{\\num{ 201277 }  }{\\num{ 0.774 } }$  \n",
       "Pretrained  $\\underset{\\num{ 201613 }  }{\\num{ 0.775 } }$  \n",
       "Custom      $\\underset{\\num{ 230706 }  }{\\num{ 0.887 } }$  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = all_decays_imbalanced.index\n",
    "exp_str_array = np.zeros((5, 6), dtype=object)\n",
    "for i,row in enumerate(rows):\n",
    "    exp_str_array[i, 0] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays.loc[row][\"Predicted single\"],\n",
    "        all_decays.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 1] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays.loc[row][\"Predicted double\"],\n",
    "        all_decays.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 2] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_pmod.loc[row][\"Predicted single\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 3] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_pmod.loc[row][\"Predicted double\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 4] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_imbalanced.loc[row][\"Predicted single\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 5] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_imbalanced.loc[row][\"Predicted double\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "\n",
    "cols = [\"Single (a)\",\"Double (a)\", \"Single (b)\", \"Double (b)\", \"Single (c)\",\"Double (c)\"]\n",
    "exp_df = pd.DataFrame(exp_str_array, columns=cols, index=rows)\n",
    "display(exp_df)\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_ratios.tex\"\n",
    "caption = \"\"\"\n",
    "Decay event classification on experimental data, with models trained on:\n",
    "a) unmodified data, b) data where specific pixels are set to zero to mimic\n",
    "'dead' pixels in experimental data, and c) same as b) and imbalanced to mimic experimental data.\n",
    "The numbers are shown as the normalized ratio of predicted event type, with the actual amount of\n",
    "events predicted of that type below.\n",
    "\"\"\"\n",
    "label = \"tab:classification-experimental-ratios\"\n",
    "with open(fname, \"w\") as fp:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    exp_df.to_latex(fp, escape=False, caption=caption, label=label, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single (a)</th>\n",
       "      <th>Double (a)</th>\n",
       "      <th>Single (b)</th>\n",
       "      <th>Double (b)</th>\n",
       "      <th>Single (c)</th>\n",
       "      <th>Double (c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 4 }  }{\\num{ 0.235 } }$</td>\n",
       "      <td>$\\underset{\\num{ 13 }  }{\\num{ 0.765 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Single (a)  \\\n",
       "Logistic    $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$    \n",
       "Dense       $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$    \n",
       "CNN         $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$    \n",
       "Custom      $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$    \n",
       "\n",
       "                                           Double (a)  \\\n",
       "Logistic    $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Dense       $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "CNN         $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$    \n",
       "Pretrained  $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Custom      $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "\n",
       "                                          Single (b)  \\\n",
       "Logistic    $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Dense       $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "CNN         $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Custom      $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "\n",
       "                                           Double (b)  \\\n",
       "Logistic    $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Dense       $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "CNN         $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Custom      $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "\n",
       "                                          Single (c)  \\\n",
       "Logistic    $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Dense       $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "CNN         $\\underset{\\num{ 4 }  }{\\num{ 0.235 } }$   \n",
       "Pretrained  $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Custom      $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "\n",
       "                                           Double (c)  \n",
       "Logistic    $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  \n",
       "Dense       $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  \n",
       "CNN         $\\underset{\\num{ 13 }  }{\\num{ 0.765 } }$  \n",
       "Pretrained  $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  \n",
       "Custom      $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = all_labeled_doubles_imbalanced.index\n",
    "exp_str_array = np.zeros((5, 6), dtype=object)\n",
    "for i,row in enumerate(rows):\n",
    "    exp_str_array[i, 0] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles.loc[row][\"Predicted single\"],\n",
    "        all_labeled_doubles.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 1] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles.loc[row][\"Predicted double\"],\n",
    "        all_labeled_doubles.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 2] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_pmod.loc[row][\"Predicted single\"],\n",
    "        all_labeled_doubles_pmod.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 3] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_pmod.loc[row][\"Predicted double\"],\n",
    "        all_labeled_doubles_pmod.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 4] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Predicted single\"],\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 5] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Predicted double\"],\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "\n",
    "cols = [\"Single (a)\",\"Double (a)\", \"Single (b)\", \"Double (b)\", \"Single (c)\",\"Double (c)\"]\n",
    "exp_df = pd.DataFrame(exp_str_array, columns=cols, index=rows)\n",
    "display(exp_df)\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_labeled_doubles.tex\"\n",
    "caption = \"\"\"\n",
    "Decay event classification on 17 labeled samples of experimental data. The 17 samples are all\n",
    "labeled as double events. Models are trained on simulated data with a varying degree of modification:\n",
    "a) unmodified data, b) data where specific pixels are set to zero to mimic\n",
    "'dead' pixels in experimental data, and c) same as b) and imbalanced to mimic experimental data.\n",
    "The numbers are shown as the normalized ratio of predicted event type, with the actual amount of\n",
    "events predicted of that type below.\n",
    "\"\"\"\n",
    "label = \"tab:classification-experimental-labeled-doubles\"\n",
    "with open(fname, \"w\") as fp:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    exp_df.to_latex(fp, escape=False, caption=caption, label=label, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraction of predicted single events for each model, as a function of total pixel intensity\n",
    "These plots serve as another view of where the predictions of single events happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "key_translator = {\n",
    "    'log_test_i': 'Logistic',\n",
    "    'dense_test_i': 'Dense',\n",
    "    'cnn_test_i': 'CNN',\n",
    "    'pretrained_test_i': 'Pretrained',\n",
    "    'custom_test_i': 'Custom',\n",
    "    'log_test_ii': 'Logistic',\n",
    "    'dense_test_ii': 'Dense',\n",
    "    'cnn_test_ii': 'CNN',\n",
    "    'pretrained_test_ii': 'Pretrained',\n",
    "    'custom_test_ii': 'Custom',\n",
    "    'log_test_iii': 'Logistic',\n",
    "    'dense_test_iii': 'Dense',\n",
    "    'cnn_test_iii': 'CNN',\n",
    "    'pretrained_test_iii': 'Pretrained',\n",
    "    'custom_test_iii': 'Custom',\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(8, 3), sharex=True, sharey=True)\n",
    "for k, v in HIST_DICT.items():\n",
    "    bins = v[0]\n",
    "    counts = v[1]\n",
    "    if k.endswith('_i'):\n",
    "        ax[0].plot(bins[:-1], counts/sum(counts), label=key_translator[k])\n",
    "    if k.endswith('_ii'):\n",
    "        ax[1].plot(bins[:-1], counts/sum(counts), label=key_translator[k])\n",
    "    if k.endswith('_iii'):\n",
    "        ax[2].plot(bins[:-1], counts/sum(counts), label=key_translator[k])\n",
    "\n",
    "ax[0].set_ylabel(\"Fraction of single events\", fontsize=13)\n",
    "ax[0].set_title(\"Dataset (a)\")\n",
    "ax[0].legend(fontsize=12)\n",
    "ax[1].set_title(\"Dataset (b)\")\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[2].set_title(\"Dataset (c)\")\n",
    "ax[2].legend(fontsize=12)\n",
    "ax[0].set_xlim(0, 6)\n",
    "fig.text(0.5, 0, \"Total pixel intensity in image\", ha='center', fontsize=13)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_single_fractions.pdf\"\n",
    "fig.savefig(fname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Alternative figure setup\n",
    "\n",
    "key_translator = {\n",
    "    'log_test_i': 'Logistic',\n",
    "    'dense_test_i': 'Dense',\n",
    "    'cnn_test_i': 'CNN',\n",
    "    'pretrained_test_i': 'Pretrained',\n",
    "    'custom_test_i': 'Custom',\n",
    "    'log_test_ii': 'Logistic',\n",
    "    'dense_test_ii': 'Dense',\n",
    "    'cnn_test_ii': 'CNN',\n",
    "    'pretrained_test_ii': 'Pretrained',\n",
    "    'custom_test_ii': 'Custom',\n",
    "    'log_test_iii': 'Logistic',\n",
    "    'dense_test_iii': 'Dense',\n",
    "    'cnn_test_iii': 'CNN',\n",
    "    'pretrained_test_iii': 'Pretrained',\n",
    "    'custom_test_iii': 'Custom',\n",
    "}\n",
    "\n",
    "fig1 = plt.figure(figsize=(8,6))\n",
    "ax1 = plt.subplot2grid(shape=(2,4), loc=(0,0), colspan=2, fig=fig1)\n",
    "ax2 = plt.subplot2grid((2,4), (0,2), colspan=2, fig=fig1)\n",
    "ax3 = plt.subplot2grid((2,4), (1,1), colspan=2, fig=fig1)\n",
    "for k, v in HIST_DICT.items():\n",
    "    bins = v[0]\n",
    "    counts = v[1]\n",
    "    if k.endswith('_i'):\n",
    "        ax1.plot(bins[:-1], counts/sum(counts), label=key_translator[k])\n",
    "    if k.endswith('_ii'):\n",
    "        ax2.plot(bins[:-1], counts/sum(counts), label=key_translator[k])\n",
    "    if k.endswith('_iii'):\n",
    "        ax3.plot(bins[:-1], counts/sum(counts), label=key_translator[k])\n",
    "        \n",
    "ax1.set_ylabel(\"Fraction of single events\", fontsize=13)\n",
    "ax1.set_title(\"Dataset (a)\")\n",
    "ax1.set_xlim(0, 6)\n",
    "ax1.legend()\n",
    "ax2.set_title(\"Dataset (b)\")\n",
    "ax2.set_xlim(0, 6)\n",
    "ax2.legend()\n",
    "ax3.set_title(\"Dataset (c)\")\n",
    "ax3.set_xlim(0, 6)\n",
    "ax3.legend()\n",
    "\n",
    "fig.text(0.5, 0, \"Total pixel intensity in image\", ha='center', fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OLD)Specific models with very reasonable amount of predicted doubles\n",
    "Three models trained on imbalanced data showed a promising ratio of singles to doubles in their\n",
    "predictions, with:\n",
    "* Logistic regression - 2\n",
    "* Dense network - 25\n",
    "* Pretrained - 699\n",
    "\n",
    "Coupled with the information that they specifically also predicted most or all of the labeled doubles\n",
    "as doubles, we take a slightly deeper look into these three.\n",
    "\n",
    "* Are they predicting the same events as doubles?\n",
    "* Limited manual inspection of predicted doubles?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load logistic classification experiment\n",
    "log_ex_id = \"f7f88d576358\"\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "print(\"Predicting with log_model...\")\n",
    "log_events = classify(log_model, images_real.reshape(images_real.shape[0], 256), events)\n",
    "print(\"Done.\")\n",
    "del log_model\n",
    "\n",
    "log_doubles = [e_id for e_id in decays if log_events[e_id]['event_class'] == 'double']\n",
    "print(\"Logistic found:\", len(log_doubles))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load dense classification experiment\n",
    "dense_ex_id = \"eda9d70f103d\"\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "print(\"Predicting with dense_model...\")\n",
    "dense_events = classify(dense_model, images_real.reshape(images_real.shape[0], 256), events)\n",
    "print(\"Done.\")\n",
    "del dense_model\n",
    "\n",
    "dense_doubles = [e_id for e_id in decays if dense_events[e_id][\"event_class\"] == 'double']\n",
    "print(\"Dense found:\", len(dense_doubles))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load pretrained classification experiment\n",
    "pretrained_ex_id = \"63d7c8bf7564\"\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "print(\"Predicting with pretrained_model...\")\n",
    "pretrained_events = classify(pretrained_model, np.concatenate((images_real, images_real, images_real), axis=-1), events)\n",
    "print(\"Done.\")\n",
    "del pretrained_model\n",
    "\n",
    "pretrained_doubles = [e_id for e_id in decays if pretrained_events[e_id][\"event_class\"] == 'double']\n",
    "print(\"Pretrained found:\", len(pretrained_doubles))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(set(log_doubles).intersection(set(dense_doubles))))\n",
    "print(len(set(log_doubles).intersection(set(pretrained_doubles))))\n",
    "print(len(set(dense_doubles).intersection(set(pretrained_doubles))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(6,8))\n",
    "ax[0].imshow(images_real[events[log_doubles[0]]['image_idx']].reshape(16,16))\n",
    "ax[0].set_title(log_doubles[0])\n",
    "ax[1].imshow(images_real[events[log_doubles[1]]['image_idx']].reshape(16,16))\n",
    "ax[1].set_title(log_doubles[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(5,5, figsize=(15,15))\n",
    "for i, ev in enumerate(dense_doubles):\n",
    "    sns.heatmap(images_real[events[ev]['image_idx']].reshape(16,16), square=True, cbar=True, ax=ax.flatten()[i])\n",
    "    #ax.flatten()[i].imshow(images_real[events[ev]['image_idx']].reshape(16,16), origin='lower')\n",
    "    ax.flatten()[i].set_title(ev)\n",
    "    ax.flatten()[i].invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OLD)Check location of HIP for predicted doubles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pretrained_d_idx = np.array([pretrained_events[e_id]['image_idx'] for e_id in pretrained_doubles])\n",
    "max_idx = images_real[pretrained_d_idx].reshape(images_real[pretrained_d_idx].shape[0],-1).argmax(1)\n",
    "# Get unravel indices corresponding to original shape of A\n",
    "maxpos_vect = np.column_stack(np.unravel_index(max_idx, images_real[pretrained_d_idx].shape))\n",
    "img = np.zeros(images_real[0].shape, dtype=int)\n",
    "for el in maxpos_vect:\n",
    "    img[el[1], el[2]] += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(img.reshape(16,16), square=True, annot=True, fmt='d', ax=ax)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot pretrained doubles that do not have highest pixel in bottom.\n",
    "pretrained_maxpos_select = [i for i in range(len(maxpos_vect)) if maxpos_vect[i,1] < 12 and maxpos_vect[i,2] < 12]\n",
    "\n",
    "fig, ax = plt.subplots(14,10, figsize=(16,16), sharex=True, sharey=True)\n",
    "\n",
    "i = 0\n",
    "for idx in pretrained_maxpos_select:\n",
    "    img_id = pretrained_d_idx[idx]\n",
    "    img = images_real[img_id].reshape(16,16)\n",
    "    ax.flatten()[i-i0].imshow(img)\n",
    "    ax.flatten()[i-i0].set_title(img_id)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot the labeled doubles\n",
    "labeled_doubles = [e_id for e_id in events.keys() if events[e_id]['event_descriptor'] == 16]\n",
    "fig, ax = plt.subplots(5,4, figsize=(12,12), sharex=True)\n",
    "for i, ev in enumerate(labeled_doubles):\n",
    "    ax.flatten()[i].imshow(images_real[events[ev]['image_idx']].reshape(16,16))\n",
    "    ax.flatten()[i].set_title(ev)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Events for export to sample for thesis\n",
    "for k, e in events.items():\n",
    "    if e['image_idx'] == 221454: print(k)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#events, images = import_real_data(repo_root + \"data/real/anodedata_500k.txt\") # images not normalized\n",
    "d_easy = images_real[events[156699]['image_idx']]\n",
    "d_hard = images_real[events[478726]['image_idx']]\n",
    "s = images_real[events[929592]['image_idx']]\n",
    "\n",
    "export = np.array([s, d_easy, d_hard])\n",
    "np.save(repo_root + \"data/real/samples_thesis\", export)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rows = all_decays_imbalanced.index\n",
    "exp_str_array = np.zeros((5, 3), dtype=object)\n",
    "for i,row in enumerate(rows):\n",
    "    exp_str_array[i, 0] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$,   $\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays.loc[row][\"Predicted single\"],\n",
    "        all_decays.loc[row][\"Normalized single\"],\n",
    "        all_decays.loc[row][\"Predicted double\"],\n",
    "        all_decays.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 1] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$,   $\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_pmod.loc[row][\"Predicted single\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized single\"],\n",
    "        all_decays_pmod.loc[row][\"Predicted double\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 2] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$,   $\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_imbalanced.loc[row][\"Predicted single\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized single\"],\n",
    "        all_decays_imbalanced.loc[row][\"Predicted double\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "\n",
    "cols = [\"Single, Double (a)\", \"Single, Double (b)\", \"Single, Double (c)\"]\n",
    "exp_df = pd.DataFrame(exp_str_array, columns=cols, index=rows)\n",
    "display(exp_df)\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_ratios.tex\"\n",
    "caption = \"\"\"\n",
    "Decay event classification on experimental data, with models trained on:\n",
    "a) unmodified data, b) data where specific pixels are set to zero to mimic\n",
    "'dead' pixels in experimental data, and c) same as b) and imbalanced to mimic experimental data.\n",
    "\"\"\"\n",
    "label = \"tab:classification-experimental-ratios\"\n",
    "with open(fname, \"w\") as fp:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    exp_df.to_latex(fp, escape=False, caption=caption, label=label, index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
