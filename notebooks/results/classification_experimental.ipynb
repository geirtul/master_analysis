{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Classification on experimental data\n",
    "This notebook is the primary source of plots and tables for the classificationn part of the thesis, \n",
    "with the goal of keeping every table and figure as standardized as possible. \n",
    "## Questions\n",
    "* Descriptive statistics\n",
    "    - Should descriptive statistics of the simulated data be included?\\\n",
    "    If so, how much? And should it be included for each fold in the k-fold cross-validation?\n",
    "* Classification results\n",
    "    - Breakdown of results based on event type? Single, double, close double?\n",
    "    Reasonable to include in order to confirm the assumption that close doubles are the\n",
    "    most difficult event type to classify correctly in simulated data\n",
    "    Random state is included, so should be simple to reproduce the indices\n",
    "\n",
    "\n",
    "## Handy links\n",
    "* [matplotlib-plots to latex](https://timodenk.com/blog/exporting-matplotlib-plots-to-latex/)\n",
    "* [Robert's thesis df output](https://github.com/ATTPC/VAE-event-classification/blob/master/src/make_classification_table.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from master_scripts.data_functions import *\n",
    "from master_scripts.analysis_functions import *\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "THESIS_PATH = \"../../../master_thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental set and normalize\n",
    "repo_root = get_git_root()\n",
    "events, images = import_real_data(repo_root + \"data/real/anodedata_500k.txt\") # images not normalized\n",
    "images = normalize_image_data(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(model, images, events, name, threshold=0.5):\n",
    "    # Get prediction and make class labels based on threshold of 0.5\n",
    "    y_out = model.predict(images)\n",
    "    y_pred = (y_out > threshold).astype(int)\n",
    "    for event_id in events.keys():\n",
    "        if y_pred[events[event_id]['image_idx']] == 0:\n",
    "            events[event_id]['event_class'] = \"single\"\n",
    "        else:\n",
    "            events[event_id]['event_class'] = \"double\"\n",
    "            \n",
    "    descriptors = list(set([event['event_descriptor'] for event in events.values()]))\n",
    "    \n",
    "    desc_class = {'single': [], 'double': []}\n",
    "    for event in events.values():\n",
    "        desc_class[event['event_class']].append(event['event_descriptor'])\n",
    "    \n",
    "    translate_descriptor = {\n",
    "        1: \"Implant\",\n",
    "        2: \"Decay\",\n",
    "        3: \"implant + Decay\",\n",
    "        4: \"Light ion\",\n",
    "        5: \"Implant + Light Ion\",\n",
    "        6: \"Decay + Light Ion\",\n",
    "        7: \"Implant + Decay + Light Ion\",\n",
    "        8: \"Double (time)\",\n",
    "        9: \"Implant + Double (time)\",\n",
    "        10: \"Decay + Double (time)\",\n",
    "        11: \"Implant + Decay + Double (time)\",\n",
    "        12: \"Light ion + Double (time)\",\n",
    "        13: \"Implant + Light Ion + Double (time)\",\n",
    "        14: \"Decay + Light ion + Double (time)\",\n",
    "        15: \"Implant + Decay + Light Ion + Double (time)\",\n",
    "        16: \"Double (space)\",\n",
    "        17: \"Implant + Double (space)\",\n",
    "        18: \"Decay + Double (space)\"\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for d in descriptors:\n",
    "        num_s = desc_class['single'].count(d)\n",
    "        num_d = desc_class['double'].count(d)\n",
    "        tot = num_s + num_d\n",
    "        norm_s = num_s / tot\n",
    "        norm_d = num_d / tot\n",
    "        results[translate_descriptor[d]] = [\n",
    "            num_s,\n",
    "            num_d,\n",
    "            norm_s,\n",
    "            norm_d\n",
    "        ]\n",
    "    \n",
    "    cols = [\"Predicted single\", \"Predicted double\", \"Normalized single\", \"Normalized double\"]\n",
    "    df = pd.DataFrame.from_dict(data=results, orient='index', columns=cols)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed simulated data - no additional modifications\n",
    "This is the basic metrics for all the models trained on simulated data.\n",
    "The basic pre-processing includes formatting and min-max normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "log_ex_id = \"003e1b62336e\"\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "\n",
    "# Load model and predict\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "log_test = classification_metrics(log_model, images.reshape(images.shape[0], 256), events, \"log_test\")\n",
    "del log_model #No longer needed, clear memory just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "dense_ex_id = \"c19117f62bd8\"\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "dense_test = classification_metrics(dense_model, images.reshape(images.shape[0], 256), events, \"dense_test\")\n",
    "del dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "cnn_ex_id = \"b56e64ac3b1c\"\n",
    "cnn_ex = load_experiment(cnn_ex_id)\n",
    "cnn_model = tf.keras.models.load_model(repo_root + \"models/\" + cnn_ex_id + \".h5\", compile=False)\n",
    "cnn_test = classification_metrics(cnn_model, images, events, \"cnn_test\")\n",
    "del cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained - VGG\n",
    "As an additional baseline for performance, we include a pretrained SOTA network\n",
    "where trained on the ImageNet database.\n",
    "\n",
    "Due to the size of our detector images (16x16) compared with the size the VGG network is\n",
    "designed for, we cannot use all layers in the VGG network. This stems from the use of max-pooling\n",
    "which effectively reduces the image size to half (8x8) each time the input is passed through such a\n",
    "layer. At some point our input is too small to pass through to the rest of the network.\n",
    "We therefore cut the network at the point where this becomes and issue.\n",
    "Alternatively, one could possibly keep the depth but remove max-pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained regression experiment\n",
    "pretrained_ex_id = \"c96f61c743c2\"\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "pretrained_test = classification_metrics(pretrained_model, np.concatenate((images, images, images), axis=-1), events, \"pretrained_test\")\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom classification experiment\n",
    "custom_ex_id = \"424cc250c5ab\"\n",
    "custom_ex = load_experiment(custom_ex_id)\n",
    "custom_model = tf.keras.models.load_model(repo_root + \"models/\" + custom_ex_id + \".h5\", compile=False)\n",
    "custom_test = classification_metrics(custom_model, images, events, \"custom_test\")\n",
    "del custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the metrics into one table\n",
    "We use the standard deviation in the folds as an error measure, and report the mean classification f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>198210.0</td>\n",
       "      <td>61937.0</td>\n",
       "      <td>0.761915</td>\n",
       "      <td>0.238085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>97487.0</td>\n",
       "      <td>162660.0</td>\n",
       "      <td>0.374738</td>\n",
       "      <td>0.625262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>63051.0</td>\n",
       "      <td>197096.0</td>\n",
       "      <td>0.242367</td>\n",
       "      <td>0.757633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>138614.0</td>\n",
       "      <td>121533.0</td>\n",
       "      <td>0.532830</td>\n",
       "      <td>0.467170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>26277.0</td>\n",
       "      <td>233870.0</td>\n",
       "      <td>0.101008</td>\n",
       "      <td>0.898992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    198210.0          61937.0           0.761915            \n",
       "Dense       97487.0           162660.0          0.374738            \n",
       "CNN         63051.0           197096.0          0.242367            \n",
       "Pretrained  138614.0          121533.0          0.532830            \n",
       "Custom      26277.0           233870.0          0.101008            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.238085           \n",
       "Dense       0.625262           \n",
       "CNN         0.757633           \n",
       "Pretrained  0.467170           \n",
       "Custom      0.898992           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    0.0               17.0              0.0                 \n",
       "Dense       0.0               17.0              0.0                 \n",
       "CNN         0.0               17.0              0.0                 \n",
       "Pretrained  0.0               17.0              0.0                 \n",
       "Custom      0.0               17.0              0.0                 \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    1.0                \n",
       "Dense       1.0                \n",
       "CNN         1.0                \n",
       "Pretrained  1.0                \n",
       "Custom      1.0                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_decays = pd.DataFrame.from_dict(\n",
    "    data={\n",
    "        'Logistic': log_test.iloc[1],\n",
    "        'Dense': dense_test.iloc[1],\n",
    "        'CNN': cnn_test.iloc[1],\n",
    "        'Pretrained': pretrained_test.iloc[1],\n",
    "        'Custom': custom_test.iloc[1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "all_labeled_doubles = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "        'Logistic': log_test.iloc[-1],\n",
    "        'Dense': dense_test.iloc[-1],\n",
    "        'CNN': cnn_test.iloc[-1],\n",
    "        'Pretrained': pretrained_test.iloc[-1],\n",
    "        'Custom': custom_test.iloc[-1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "display(all_decays)\n",
    "display(all_labeled_doubles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed simulated data - Pixel modified\n",
    "The basic pre-processing includes formatting and min-max normalization.\n",
    "Additionally, the data has had the top and bottom lines of pixels set to 0, plus\n",
    "one pixel inside the detector permanently 0 (which idx again?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "log_ex_id = \"b89547da983e\"\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "\n",
    "# Load model\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "log_test_pmod = classification_metrics(log_model, images.reshape(images.shape[0], 256), events, \"log_test\")\n",
    "del log_model #No longer needed, clear memory just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "dense_ex_id = \"bc4937925065\"\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "dense_test_pmod = classification_metrics(dense_model, images.reshape(images.shape[0], 256), events, \"dense_test\")\n",
    "del dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "cnn_ex_id = \"2b135384dd50\"\n",
    "cnn_ex = load_experiment(cnn_ex_id)\n",
    "cnn_model = tf.keras.models.load_model(repo_root + \"models/\" + cnn_ex_id + \".h5\", compile=False)\n",
    "cnn_test_pmod = classification_metrics(cnn_model, images, events, \"cnn_test\")\n",
    "del cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained - VGG\n",
    "As an additional baseline for performance, we include a pretrained SOTA network\n",
    "where trained on the ImageNet database.\n",
    "\n",
    "Due to the size of our detector images (16x16) compared with the size the VGG network is\n",
    "designed for, we cannot use all layers in the VGG network. This stems from the use of max-pooling\n",
    "which effectively reduces the image size to half (8x8) each time the input is passed through such a\n",
    "layer. At some point our input is too small to pass through to the rest of the network.\n",
    "We therefore cut the network at the point where this becomes and issue.\n",
    "Alternatively, one could possibly keep the depth but remove max-pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "pretrained_ex_id = \"6bc44ed76ea7\"\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "pretrained_test_pmod = classification_metrics(pretrained_model, np.concatenate((images, images, images), axis=-1), events, \"pretrained_test\")\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom classification experiment\n",
    "custom_ex_id = \"60f95ed56212\"\n",
    "custom_ex = load_experiment(custom_ex_id)\n",
    "custom_model = tf.keras.models.load_model(repo_root + \"models/\" + custom_ex_id + \".h5\", compile=False)\n",
    "custom_test_pmod = classification_metrics(custom_model, images, events, \"custom_test\")\n",
    "del custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the metrics into one table\n",
    "We use the standard deviation in the folds as an error measure, and report the mean classification f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>202426.0</td>\n",
       "      <td>57721.0</td>\n",
       "      <td>0.778122</td>\n",
       "      <td>0.221878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>100778.0</td>\n",
       "      <td>159369.0</td>\n",
       "      <td>0.387389</td>\n",
       "      <td>0.612611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>66790.0</td>\n",
       "      <td>193357.0</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.743261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>137765.0</td>\n",
       "      <td>122382.0</td>\n",
       "      <td>0.529566</td>\n",
       "      <td>0.470434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>24738.0</td>\n",
       "      <td>235409.0</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>0.904908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    202426.0          57721.0           0.778122            \n",
       "Dense       100778.0          159369.0          0.387389            \n",
       "CNN         66790.0           193357.0          0.256739            \n",
       "Pretrained  137765.0          122382.0          0.529566            \n",
       "Custom      24738.0           235409.0          0.095092            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.221878           \n",
       "Dense       0.612611           \n",
       "CNN         0.743261           \n",
       "Pretrained  0.470434           \n",
       "Custom      0.904908           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    0.0               17.0              0.0                 \n",
       "Dense       0.0               17.0              0.0                 \n",
       "CNN         0.0               17.0              0.0                 \n",
       "Pretrained  0.0               17.0              0.0                 \n",
       "Custom      0.0               17.0              0.0                 \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    1.0                \n",
       "Dense       1.0                \n",
       "CNN         1.0                \n",
       "Pretrained  1.0                \n",
       "Custom      1.0                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_decays_pmod = pd.DataFrame.from_dict(\n",
    "    data={\n",
    "        'Logistic': log_test_pmod.iloc[1],\n",
    "        'Dense': dense_test_pmod.iloc[1],\n",
    "        'CNN': cnn_test_pmod.iloc[1],\n",
    "        'Pretrained': pretrained_test_pmod.iloc[1],\n",
    "        'Custom': custom_test_pmod.iloc[1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "all_labeled_doubles_pmod = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "        'Logistic': log_test_pmod.iloc[-1],\n",
    "        'Dense': dense_test_pmod.iloc[-1],\n",
    "        'CNN': cnn_test_pmod.iloc[-1],\n",
    "        'Pretrained': pretrained_test_pmod.iloc[-1],\n",
    "        'Custom': custom_test_pmod.iloc[-1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "display(all_decays_pmod)\n",
    "display(all_labeled_doubles_pmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processed simulated data - Pixel modified and imbalanced\n",
    "The basic pre-processing includes formatting and min-max normalization.\n",
    "Additionally, the data has had the top and bottom lines of pixels set to 0, plus\n",
    "one pixel inside the detector permanently 0 (which idx again?).\n",
    "\n",
    "This dataset has also been purposefully imbalanced to mimic the properties of experimental data\n",
    "where doubles in space are expected to be rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "log_ex_id = \"f7f88d576358\"\n",
    "log_ex = load_experiment(log_ex_id)\n",
    "\n",
    "# Load model\n",
    "log_model = tf.keras.models.load_model(repo_root + \"models/\" + log_ex_id + \".h5\", compile=False)\n",
    "log_test_imbalanced = classification_metrics(log_model, images.reshape(images.shape[0], 256), events, \"log_test\")\n",
    "del log_model #No longer needed, clear memory just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "dense_ex_id = \"eda9d70f103d\"\n",
    "dense_ex = load_experiment(dense_ex_id)\n",
    "dense_model = tf.keras.models.load_model(repo_root + \"models/\" + dense_ex_id + \".h5\", compile=False)\n",
    "dense_test_imbalanced = classification_metrics(dense_model, images.reshape(images.shape[0], 256), events, \"dense_test\")\n",
    "del dense_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "cnn_ex_id = \"fbec3ae91aaa\"\n",
    "cnn_ex = load_experiment(cnn_ex_id)\n",
    "cnn_model = tf.keras.models.load_model(repo_root + \"models/\" + cnn_ex_id + \".h5\", compile=False)\n",
    "cnn_test_imbalanced = classification_metrics(cnn_model, images, events, \"cnn_test\")\n",
    "del cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained - VGG\n",
    "As an additional baseline for performance, we include a pretrained SOTA network\n",
    "where trained on the ImageNet database.\n",
    "\n",
    "Due to the size of our detector images (16x16) compared with the size the VGG network is\n",
    "designed for, we cannot use all layers in the VGG network. This stems from the use of max-pooling\n",
    "which effectively reduces the image size to half (8x8) each time the input is passed through such a\n",
    "layer. At some point our input is too small to pass through to the rest of the network.\n",
    "We therefore cut the network at the point where this becomes and issue.\n",
    "Alternatively, one could possibly keep the depth but remove max-pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logistic regression experiment\n",
    "pretrained_ex_id = \"63d7c8bf7564\"\n",
    "pretrained_ex = load_experiment(pretrained_ex_id)\n",
    "pretrained_model = tf.keras.models.load_model(repo_root + \"models/\" + pretrained_ex_id + \".h5\", compile=False)\n",
    "pretrained_test_imbalanced = classification_metrics(pretrained_model, np.concatenate((images, images, images), axis=-1), events, \"pretrained_test\")\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom classification experiment\n",
    "custom_ex_id = \"5f6eef7315ab\"\n",
    "custom_ex = load_experiment(custom_ex_id)\n",
    "custom_model = tf.keras.models.load_model(repo_root + \"models/\" + custom_ex_id + \".h5\", compile=False)\n",
    "custom_test_imbalanced = classification_metrics(custom_model, images, events, \"custom_test\")\n",
    "del custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the metrics into one table\n",
    "We use the standard deviation in the folds as an error measure, and report the mean classification f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>260145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>260122.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>98594.0</td>\n",
       "      <td>161553.0</td>\n",
       "      <td>0.378993</td>\n",
       "      <td>0.621007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>259448.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>0.002687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>52951.0</td>\n",
       "      <td>207196.0</td>\n",
       "      <td>0.203543</td>\n",
       "      <td>0.796457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    260145.0          2.0               0.999992            \n",
       "Dense       260122.0          25.0              0.999904            \n",
       "CNN         98594.0           161553.0          0.378993            \n",
       "Pretrained  259448.0          699.0             0.997313            \n",
       "Custom      52951.0           207196.0          0.203543            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.000008           \n",
       "Dense       0.000096           \n",
       "CNN         0.621007           \n",
       "Pretrained  0.002687           \n",
       "Custom      0.796457           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted single</th>\n",
       "      <th>Predicted double</th>\n",
       "      <th>Normalized single</th>\n",
       "      <th>Normalized double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted single  Predicted double  Normalized single  \\\n",
       "Logistic    1.0               16.0              0.058824            \n",
       "Dense       0.0               17.0              0.000000            \n",
       "CNN         0.0               17.0              0.000000            \n",
       "Pretrained  3.0               14.0              0.176471            \n",
       "Custom      0.0               17.0              0.000000            \n",
       "\n",
       "            Normalized double  \n",
       "Logistic    0.941176           \n",
       "Dense       1.000000           \n",
       "CNN         1.000000           \n",
       "Pretrained  0.823529           \n",
       "Custom      1.000000           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_decays_imbalanced = pd.DataFrame.from_dict(\n",
    "    data={\n",
    "        'Logistic': log_test_imbalanced.iloc[1],\n",
    "        'Dense': dense_test_imbalanced.iloc[1],\n",
    "        'CNN': cnn_test_imbalanced.iloc[1],\n",
    "        'Pretrained': pretrained_test_imbalanced.iloc[1],\n",
    "        'Custom': custom_test_imbalanced.iloc[1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "all_labeled_doubles_imbalanced = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "        'Logistic': log_test_imbalanced.iloc[-1],\n",
    "        'Dense': dense_test_imbalanced.iloc[-1],\n",
    "        'CNN': cnn_test_imbalanced.iloc[-1],\n",
    "        'Pretrained': pretrained_test_imbalanced.iloc[-1],\n",
    "        'Custom': custom_test_imbalanced.iloc[-1],\n",
    "    },\n",
    "    orient='index'\n",
    ")\n",
    "\n",
    "display(all_decays_imbalanced)\n",
    "display(all_labeled_doubles_imbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single (a)</th>\n",
       "      <th>Double (a)</th>\n",
       "      <th>Single (b)</th>\n",
       "      <th>Double (b)</th>\n",
       "      <th>Single (c)</th>\n",
       "      <th>Double (c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>$\\underset{\\num{ 198210 }  }{\\num{ 0.762 } }$</td>\n",
       "      <td>$\\underset{\\num{ 61937 }  }{\\num{ 0.238 } }$</td>\n",
       "      <td>$\\underset{\\num{ 202426 }  }{\\num{ 0.778 } }$</td>\n",
       "      <td>$\\underset{\\num{ 57721 }  }{\\num{ 0.222 } }$</td>\n",
       "      <td>$\\underset{\\num{ 260145 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 2 }  }{\\num{ 0.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>$\\underset{\\num{ 97487 }  }{\\num{ 0.375 } }$</td>\n",
       "      <td>$\\underset{\\num{ 162660 }  }{\\num{ 0.625 } }$</td>\n",
       "      <td>$\\underset{\\num{ 100778 }  }{\\num{ 0.387 } }$</td>\n",
       "      <td>$\\underset{\\num{ 159369 }  }{\\num{ 0.613 } }$</td>\n",
       "      <td>$\\underset{\\num{ 260122 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 25 }  }{\\num{ 0.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>$\\underset{\\num{ 63051 }  }{\\num{ 0.242 } }$</td>\n",
       "      <td>$\\underset{\\num{ 197096 }  }{\\num{ 0.758 } }$</td>\n",
       "      <td>$\\underset{\\num{ 66790 }  }{\\num{ 0.257 } }$</td>\n",
       "      <td>$\\underset{\\num{ 193357 }  }{\\num{ 0.743 } }$</td>\n",
       "      <td>$\\underset{\\num{ 98594 }  }{\\num{ 0.379 } }$</td>\n",
       "      <td>$\\underset{\\num{ 161553 }  }{\\num{ 0.621 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>$\\underset{\\num{ 138614 }  }{\\num{ 0.533 } }$</td>\n",
       "      <td>$\\underset{\\num{ 121533 }  }{\\num{ 0.467 } }$</td>\n",
       "      <td>$\\underset{\\num{ 137765 }  }{\\num{ 0.530 } }$</td>\n",
       "      <td>$\\underset{\\num{ 122382 }  }{\\num{ 0.470 } }$</td>\n",
       "      <td>$\\underset{\\num{ 259448 }  }{\\num{ 0.997 } }$</td>\n",
       "      <td>$\\underset{\\num{ 699 }  }{\\num{ 0.003 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>$\\underset{\\num{ 26277 }  }{\\num{ 0.101 } }$</td>\n",
       "      <td>$\\underset{\\num{ 233870 }  }{\\num{ 0.899 } }$</td>\n",
       "      <td>$\\underset{\\num{ 24738 }  }{\\num{ 0.095 } }$</td>\n",
       "      <td>$\\underset{\\num{ 235409 }  }{\\num{ 0.905 } }$</td>\n",
       "      <td>$\\underset{\\num{ 52951 }  }{\\num{ 0.204 } }$</td>\n",
       "      <td>$\\underset{\\num{ 207196 }  }{\\num{ 0.796 } }$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Single (a)  \\\n",
       "Logistic    $\\underset{\\num{ 198210 }  }{\\num{ 0.762 } }$   \n",
       "Dense       $\\underset{\\num{ 97487 }  }{\\num{ 0.375 } }$    \n",
       "CNN         $\\underset{\\num{ 63051 }  }{\\num{ 0.242 } }$    \n",
       "Pretrained  $\\underset{\\num{ 138614 }  }{\\num{ 0.533 } }$   \n",
       "Custom      $\\underset{\\num{ 26277 }  }{\\num{ 0.101 } }$    \n",
       "\n",
       "                                               Double (a)  \\\n",
       "Logistic    $\\underset{\\num{ 61937 }  }{\\num{ 0.238 } }$    \n",
       "Dense       $\\underset{\\num{ 162660 }  }{\\num{ 0.625 } }$   \n",
       "CNN         $\\underset{\\num{ 197096 }  }{\\num{ 0.758 } }$   \n",
       "Pretrained  $\\underset{\\num{ 121533 }  }{\\num{ 0.467 } }$   \n",
       "Custom      $\\underset{\\num{ 233870 }  }{\\num{ 0.899 } }$   \n",
       "\n",
       "                                               Single (b)  \\\n",
       "Logistic    $\\underset{\\num{ 202426 }  }{\\num{ 0.778 } }$   \n",
       "Dense       $\\underset{\\num{ 100778 }  }{\\num{ 0.387 } }$   \n",
       "CNN         $\\underset{\\num{ 66790 }  }{\\num{ 0.257 } }$    \n",
       "Pretrained  $\\underset{\\num{ 137765 }  }{\\num{ 0.530 } }$   \n",
       "Custom      $\\underset{\\num{ 24738 }  }{\\num{ 0.095 } }$    \n",
       "\n",
       "                                               Double (b)  \\\n",
       "Logistic    $\\underset{\\num{ 57721 }  }{\\num{ 0.222 } }$    \n",
       "Dense       $\\underset{\\num{ 159369 }  }{\\num{ 0.613 } }$   \n",
       "CNN         $\\underset{\\num{ 193357 }  }{\\num{ 0.743 } }$   \n",
       "Pretrained  $\\underset{\\num{ 122382 }  }{\\num{ 0.470 } }$   \n",
       "Custom      $\\underset{\\num{ 235409 }  }{\\num{ 0.905 } }$   \n",
       "\n",
       "                                               Single (c)  \\\n",
       "Logistic    $\\underset{\\num{ 260145 }  }{\\num{ 1.000 } }$   \n",
       "Dense       $\\underset{\\num{ 260122 }  }{\\num{ 1.000 } }$   \n",
       "CNN         $\\underset{\\num{ 98594 }  }{\\num{ 0.379 } }$    \n",
       "Pretrained  $\\underset{\\num{ 259448 }  }{\\num{ 0.997 } }$   \n",
       "Custom      $\\underset{\\num{ 52951 }  }{\\num{ 0.204 } }$    \n",
       "\n",
       "                                               Double (c)  \n",
       "Logistic    $\\underset{\\num{ 2 }  }{\\num{ 0.000 } }$       \n",
       "Dense       $\\underset{\\num{ 25 }  }{\\num{ 0.000 } }$      \n",
       "CNN         $\\underset{\\num{ 161553 }  }{\\num{ 0.621 } }$  \n",
       "Pretrained  $\\underset{\\num{ 699 }  }{\\num{ 0.003 } }$     \n",
       "Custom      $\\underset{\\num{ 207196 }  }{\\num{ 0.796 } }$  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = all_decays_imbalanced.index\n",
    "exp_str_array = np.zeros((5, 6), dtype=object)\n",
    "for i,row in enumerate(rows):\n",
    "    exp_str_array[i, 0] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays.loc[row][\"Predicted single\"],\n",
    "        all_decays.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 1] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays.loc[row][\"Predicted double\"],\n",
    "        all_decays.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 2] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_pmod.loc[row][\"Predicted single\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 3] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_pmod.loc[row][\"Predicted double\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 4] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_imbalanced.loc[row][\"Predicted single\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 5] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_imbalanced.loc[row][\"Predicted double\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "\n",
    "cols = [\"Single (a)\",\"Double (a)\", \"Single (b)\", \"Double (b)\", \"Single (c)\",\"Double (c)\"]\n",
    "exp_df = pd.DataFrame(exp_str_array, columns=cols, index=rows)\n",
    "display(exp_df)\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_ratios.tex\"\n",
    "caption = \"\"\"\n",
    "Decay event classification on experimental data, with models trained on:\n",
    "a) unmodified data, b) data where specific pixels are set to zero to mimic\n",
    "'dead' pixels in experimental data, and c) same as b) and imbalanced to mimic experimental data.\n",
    "The numbers are shown as the normalized ratio of predicted event type, with the actual amount of\n",
    "events predicted of that type below.\n",
    "\"\"\"\n",
    "label = \"tab:classification-experimental-ratios\"\n",
    "with open(fname, \"w\") as fp:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    exp_df.to_latex(fp, escape=False, caption=caption, label=label, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single (a)</th>\n",
       "      <th>Double (a)</th>\n",
       "      <th>Single (b)</th>\n",
       "      <th>Double (b)</th>\n",
       "      <th>Single (c)</th>\n",
       "      <th>Double (c)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 1 }  }{\\num{ 0.059 } }$</td>\n",
       "      <td>$\\underset{\\num{ 16 }  }{\\num{ 0.941 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pretrained</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 3 }  }{\\num{ 0.176 } }$</td>\n",
       "      <td>$\\underset{\\num{ 14 }  }{\\num{ 0.824 } }$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom</th>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$</td>\n",
       "      <td>$\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Single (a)  \\\n",
       "Logistic    $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Dense       $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "CNN         $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Custom      $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "\n",
       "                                           Double (a)  \\\n",
       "Logistic    $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Dense       $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "CNN         $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Custom      $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "\n",
       "                                          Single (b)  \\\n",
       "Logistic    $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Dense       $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "CNN         $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Custom      $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "\n",
       "                                           Double (b)  \\\n",
       "Logistic    $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Dense       $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "CNN         $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "Custom      $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$   \n",
       "\n",
       "                                          Single (c)  \\\n",
       "Logistic    $\\underset{\\num{ 1 }  }{\\num{ 0.059 } }$   \n",
       "Dense       $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "CNN         $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "Pretrained  $\\underset{\\num{ 3 }  }{\\num{ 0.176 } }$   \n",
       "Custom      $\\underset{\\num{ 0 }  }{\\num{ 0.000 } }$   \n",
       "\n",
       "                                           Double (c)  \n",
       "Logistic    $\\underset{\\num{ 16 }  }{\\num{ 0.941 } }$  \n",
       "Dense       $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  \n",
       "CNN         $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  \n",
       "Pretrained  $\\underset{\\num{ 14 }  }{\\num{ 0.824 } }$  \n",
       "Custom      $\\underset{\\num{ 17 }  }{\\num{ 1.000 } }$  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = all_labeled_doubles_imbalanced.index\n",
    "exp_str_array = np.zeros((5, 6), dtype=object)\n",
    "for i,row in enumerate(rows):\n",
    "    exp_str_array[i, 0] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles.loc[row][\"Predicted single\"],\n",
    "        all_labeled_doubles.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 1] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles.loc[row][\"Predicted double\"],\n",
    "        all_labeled_doubles.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 2] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_pmod.loc[row][\"Predicted single\"],\n",
    "        all_labeled_doubles_pmod.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 3] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_pmod.loc[row][\"Predicted double\"],\n",
    "        all_labeled_doubles_pmod.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 4] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Predicted single\"],\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Normalized single\"],\n",
    "    )\n",
    "    exp_str_array[i, 5] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Predicted double\"],\n",
    "        all_labeled_doubles_imbalanced.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "\n",
    "cols = [\"Single (a)\",\"Double (a)\", \"Single (b)\", \"Double (b)\", \"Single (c)\",\"Double (c)\"]\n",
    "exp_df = pd.DataFrame(exp_str_array, columns=cols, index=rows)\n",
    "display(exp_df)\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_labeled_doubles.tex\"\n",
    "caption = \"\"\"\n",
    "Decay event classification on 17 labeled samples of experimental data. The 17 samples are all\n",
    "labeled as double events. Models are trained on simulated data with a varying degree of modification:\n",
    "a) unmodified data, b) data where specific pixels are set to zero to mimic\n",
    "'dead' pixels in experimental data, and c) same as b) and imbalanced to mimic experimental data.\n",
    "The numbers are shown as the normalized ratio of predicted event type, with the actual amount of\n",
    "events predicted of that type below.\n",
    "\"\"\"\n",
    "label = \"tab:classification-experimental-labeled-doubles\"\n",
    "with open(fname, \"w\") as fp:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    exp_df.to_latex(fp, escape=False, caption=caption, label=label, index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rows = all_decays_imbalanced.index\n",
    "exp_str_array = np.zeros((5, 3), dtype=object)\n",
    "for i,row in enumerate(rows):\n",
    "    exp_str_array[i, 0] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$,   $\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays.loc[row][\"Predicted single\"],\n",
    "        all_decays.loc[row][\"Normalized single\"],\n",
    "        all_decays.loc[row][\"Predicted double\"],\n",
    "        all_decays.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 1] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$,   $\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_pmod.loc[row][\"Predicted single\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized single\"],\n",
    "        all_decays_pmod.loc[row][\"Predicted double\"],\n",
    "        all_decays_pmod.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "    exp_str_array[i, 2] = r\"$\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$,   $\\underset{{\\num{{ {:.0f} }}  }}{{\\num{{ {:.3f} }} }}$\".format(\n",
    "        all_decays_imbalanced.loc[row][\"Predicted single\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized single\"],\n",
    "        all_decays_imbalanced.loc[row][\"Predicted double\"],\n",
    "        all_decays_imbalanced.loc[row][\"Normalized double\"],\n",
    "    )\n",
    "\n",
    "cols = [\"Single, Double (a)\", \"Single, Double (b)\", \"Single, Double (c)\"]\n",
    "exp_df = pd.DataFrame(exp_str_array, columns=cols, index=rows)\n",
    "display(exp_df)\n",
    "\n",
    "section_path = \"chapters/results/figures/\"\n",
    "fname = THESIS_PATH + section_path + \"classification_experimental_ratios.tex\"\n",
    "caption = \"\"\"\n",
    "Decay event classification on experimental data, with models trained on:\n",
    "a) unmodified data, b) data where specific pixels are set to zero to mimic\n",
    "'dead' pixels in experimental data, and c) same as b) and imbalanced to mimic experimental data.\n",
    "\"\"\"\n",
    "label = \"tab:classification-experimental-ratios\"\n",
    "with open(fname, \"w\") as fp:\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    exp_df.to_latex(fp, escape=False, caption=caption, label=label, index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
