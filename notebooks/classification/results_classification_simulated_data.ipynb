{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results from simulated data\n",
    "Deeper look into a model's performance on simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from master_scripts.data_functions import (load_experiment, get_git_root, separation_distance, energy_difference,\n",
    "                                           relative_energy, event_indices, normalize_image_data)\n",
    "from master_scripts.analysis_functions import (doubles_classification_stats, singles_classification_stats)\n",
    "from sklearn.metrics import f1_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "repo_root = get_git_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and experiment import\n",
    "Load the image data and split into training and validation sets. Since we specify the random seed, we can\n",
    "reproduce the exact same data the model was originally validated on to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(repo_root + \"data/simulated/images_full_pixelmod.npy\")\n",
    "positions = np.load(repo_root + \"data/simulated/positions_full.npy\")\n",
    "energies = np.load(repo_root + \"data/simulated/energies_full.npy\")\n",
    "labels = np.load(repo_root + \"data/simulated/labels_full.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Experiment metrics\n",
      "{\n",
      "  \"accuracy_score\": 0.9843326315789473,\n",
      "  \"confusion_matrix\": {\n",
      "    \"TN\": 236777,\n",
      "    \"FP\": 755,\n",
      "    \"FN\": 6687,\n",
      "    \"TP\": 230781\n",
      "  },\n",
      "  \"f1_score\": 0.9841323314939745,\n",
      "  \"matthews_corrcoef\": 0.9689674479424194,\n",
      "  \"roc_auc_score\": 0.9936520410947314\n",
      "}\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "# Load experiment and associated model (must be a saved model instance complete with weights)\n",
    "#experiment_id = \"40350020681b\"\n",
    "experiment_id = \"ac1722ba32d2\"\n",
    "experiment = load_experiment(experiment_id)\n",
    "model = tf.keras.models.load_model(repo_root + \"models/\" + experiment_id + \".h5\")\n",
    "# Print experiment metrics\n",
    "print(\"==== Experiment metrics\")\n",
    "print(json.dumps(experiment['metrics'], indent=2))\n",
    "print(\"====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = np.array(experiment['indices']['fold_0']['val_idx'])\n",
    "# Predict on the validation set\n",
    "prediction = model.predict(normalize_image_data(images[val_idx]))\n",
    "val_pred = (prediction > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All, close, all without close statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6349801959558057\n",
      "0.9877403830618667\n",
      "0.9841323314939745\n"
     ]
    }
   ],
   "source": [
    "s_idx, d_idx, c_idx = event_indices(positions[val_idx])\n",
    "non_close_idx = np.setdiff1d(np.concatenate((s_idx, d_idx), axis=0), c_idx)\n",
    "f1_close = f1_score(labels[val_idx][c_idx], val_pred[c_idx])\n",
    "f1_non_close = f1_score(labels[val_idx][non_close_idx], val_pred[non_close_idx])\n",
    "print(f1_close)\n",
    "print(f1_non_close)\n",
    "print(experiment['metrics']['f1_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single events\n",
    "## Descriptive stats on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "singles = singles_classification_stats(positions[val_idx], energies[val_idx], val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"TN\": 236777,\n",
      "  \"FP\": 755,\n",
      "  \"FN\": 6687,\n",
      "  \"TP\": 230781\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">x_pos</th>\n",
       "      <th colspan=\"3\" halign=\"left\">y_pos</th>\n",
       "      <th colspan=\"3\" halign=\"left\">energy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.993</td>\n",
       "      <td>4.234</td>\n",
       "      <td>7.996</td>\n",
       "      <td>8.002</td>\n",
       "      <td>4.233</td>\n",
       "      <td>8.001</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.119</td>\n",
       "      <td>3.972</td>\n",
       "      <td>8.042</td>\n",
       "      <td>7.699</td>\n",
       "      <td>3.778</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x_pos                y_pos               energy              \n",
       "                 mean    std median   mean    std median   mean    std median\n",
       "classification                                                               \n",
       "0               7.993  4.234  7.996  8.002  4.233  8.001  0.500  0.289  0.499\n",
       "1               8.119  3.972  8.042  7.699  3.778  7.631  0.733  0.205  0.768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# group by classification\n",
    "sstats = singles[singles.columns[:-1]].groupby('classification')\n",
    "# Aggregate the desired statistics into a new df\n",
    "sstats = sstats.agg([np.mean, np.std, np.median]).applymap('{:.3f}'.format)\n",
    "print(json.dumps(experiment['metrics']['confusion_matrix'], indent=2))\n",
    "display(sstats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some desired number of misclassified single event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = 16\n",
    "s_mc = singles.loc[singles['classification'] == 1]\n",
    "selected = np.random.choice(s_mc['indices'].values, n_events, replace=False)\n",
    "fig, ax = plt.subplots(np.ceil(n_events/4).astype(np.int32), 4, figsize=(16, 16))\n",
    "#fig.set_facecolor('grey')\n",
    "for i, idx in enumerate(selected):\n",
    "    a = ax.flatten()[i]\n",
    "    event = s_mc.loc[s_mc['indices'] == idx]\n",
    "    x = event['x_pos'].values[0].round(2)\n",
    "    y = event['y_pos'].values[0].round(2)\n",
    "    energy = event['energy'].values[0].round(2)\n",
    "    sns.heatmap(images[val_idx][idx].reshape(16, 16), square=True, ax=a)\n",
    "    #a.text(0, 15 + 0.6, f\"\",\n",
    "    #    fontsize=8,\n",
    "    #    color='white'\n",
    "    #    )\n",
    "    a.set_title(f\"{idx}, ({x}, {y}), E={energy}\", fontsize=10)\n",
    "    a.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check positions of all misclassified single events\n",
    "print(np.count_nonzero(positions[val_idx][s_mc['indices'].values, 2] != -100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of positions and energies\n",
    "Where are the misclassified singles located, and what are their energies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "#fig.set_facecolor('grey')\n",
    "sns.distplot(s_mc['energy'], kde=False, ax=ax[0])\n",
    "sns.scatterplot(s_mc['x_pos'], s_mc['y_pos'], alpha=0.5, ax=ax[1])\n",
    "ax[0].set_title(\"Energy distribution for singles classified as double\")\n",
    "ax[1].set_title(\"Locations of misclassified single events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double events\n",
    "## Descriptive statistics on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "doubles = doubles_classification_stats(positions[val_idx], energies[val_idx], val_pred, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by close events, then by which class the event was classified as\n",
    "dstats = doubles[doubles.columns[:-1]].groupby(['close', 'classification'])\n",
    "# Aggregate the desired statistics into a new df\n",
    "dstats = dstats.agg([np.mean, np.std, np.median, np.min, np.max]).applymap('{:.3f}'.format)\n",
    "print(json.dumps(experiment['metrics']['confusion_matrix'], indent=2))\n",
    "display(dstats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions and scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgroup = doubles.groupby(['close', 'classification'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing correct and misclassified double events\n",
    "#### Separation distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "keys = list(dgroup.groups.keys())\n",
    "sns.distplot(dgroup.get_group(keys[0])['separation distance'], kde=False, label=keys[0][1], ax=ax[0])\n",
    "sns.distplot(dgroup.get_group(keys[1])['separation distance'], kde=False, label=keys[1][1], ax=ax[0])\n",
    "sns.distplot(dgroup.get_group(keys[2])['separation distance'], kde=False, label=keys[2][1], ax=ax[1])\n",
    "sns.distplot(dgroup.get_group(keys[3])['separation distance'], kde=False, label=keys[3][1], ax=ax[1])\n",
    "ax[0].set_title(\"Separation distances for non-close events\")\n",
    "ax[0].legend()\n",
    "ax[1].set_title(\"Separation distances for close events\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgroup = doubles.groupby(['close', 'classification'])\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "keys = list(dgroup.groups.keys())\n",
    "#bins = \n",
    "sns.distplot(dgroup.get_group(keys[0])['relative energy'], kde=False, label=keys[0][1], ax=ax[0])\n",
    "sns.distplot(dgroup.get_group(keys[1])['relative energy'], kde=False, label=keys[1][1], ax=ax[0])\n",
    "sns.distplot(dgroup.get_group(keys[2])['relative energy'], kde=False, label=keys[2][1], ax=ax[1])\n",
    "sns.distplot(dgroup.get_group(keys[3])['relative energy'], kde=False, label=keys[3][1], ax=ax[1])\n",
    "ax[0].set_title(\"Relative energies for non-close events\")\n",
    "ax[0].legend()\n",
    "ax[1].set_title(\"Relative energies for close events\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "keys = list(dgroup.groups.keys())\n",
    "sns.distplot(dgroup.get_group(keys[0])['energy difference'], kde=False, label=keys[0][1], ax=ax[0])\n",
    "sns.distplot(dgroup.get_group(keys[1])['energy difference'], kde=False, label=keys[1][1], ax=ax[0])\n",
    "sns.distplot(dgroup.get_group(keys[2])['energy difference'], kde=False, label=keys[2][1], ax=ax[1])\n",
    "sns.distplot(dgroup.get_group(keys[3])['energy difference'], kde=False, label=keys[3][1], ax=ax[1])\n",
    "ax[0].set_title(\"Energy difference for non-close events\")\n",
    "ax[0].legend()\n",
    "ax[1].set_title(\"Energy difference for close events\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins = np.arange(0, np.amax(rel_distance_test), 0.5)\n",
    "energy_bins = np.arange(0, np.amax(energy_diff_test), 0.02)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "ax[0].hist(rel_distance_test[double_indices][correct_doubles], bins=dist_bins, alpha=0.5, label=\"correct\")\n",
    "ax[0].hist(rel_distance_test[double_indices][wrong_doubles], bins=dist_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[0].set_title(\"Distribution of separation distances\\n for classified double events\")\n",
    "ax[0].set_xlabel(\"Separation distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "ax[1].hist(rel_energy_test[double_indices][correct_doubles], bins=energy_bins, alpha=0.5, label=\"correct\")\n",
    "ax[1].hist(rel_energy_test[double_indices][wrong_doubles], bins=energy_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[1].set_title(\"Distribution of relative energy \\n for classified double events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "fig.savefig(FIGURE_PATH+net+\"_relative_test_compare.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins = np.arange(0, np.amax(rel_distance_test), 0.5)\n",
    "energy_bins = np.arange(0, 10, 0.1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "#ax[0].hist(rel_distance_test[double_indices][correct_doubles], bins=dist_bins, alpha=0.5, label=\"correct\")\n",
    "ax[0].hist(rel_distance_test[double_indices][wrong_doubles], bins=dist_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[0].set_title(\"Distribution of Relative distances\\n for classified double events\")\n",
    "ax[0].set_xlabel(\"Relative distance [mm]\")\n",
    "ax[0].set_ylabel(\"Number of events\")\n",
    "ax[0].legend()\n",
    "#ax[1].hist(rel_energy_test[double_indices][correct_doubles], bins=energy_bins, alpha=0.5, label=\"correct\")\n",
    "#ax[1].hist(rel_energy_test[double_indices][wrong_doubles], bins=energy_bins, alpha=0.5, label=\"wrong\")\n",
    "ax[1].hist(rel_energy_test[double_indices][wrong_doubles], label=\"wrong\")\n",
    "ax[1].set_title(\"Distribution of relative energy \\n for classified double events\")\n",
    "ax[1].set_xlabel(\"Relative energy\")\n",
    "ax[1].set_ylabel(\"Number of events\")\n",
    "ax[1].legend()\n",
    "fig.savefig(FIGURE_PATH+net+\"_relative_test_compare.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot relative distance vs. relative energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    rel_distance_test[double_indices][wrong_doubles], \n",
    "    rel_energy_test[double_indices][wrong_doubles],\n",
    "    marker='.',\n",
    "    )\n",
    "plt.title(\"Separation distance vs. relative energy for misclassified double events\")\n",
    "plt.xlabel(\"Separation distance [mm]\")\n",
    "plt.ylabel(\"Relative energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of position around highest intensity pixel\n",
    "In previous work data analysis showed that most event positions are within the highest intensity pixel,\n",
    "and all (verify!) events are within the two highest intensity pixels,\n",
    "It might be reasonable to look at how the predicted positions are distributed around the highest intensity\n",
    "pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input array to a 2D array with rows being kept as with original array.\n",
    "# Then, get idnices of max values along the columns.\n",
    "pix_hmap = np.zeros(images[0].shape)\n",
    "max_idx = images.reshape(images.shape[0],-1).argmax(1)\n",
    "# Get unravel indices corresponding to original shape of A\n",
    "maxpos_vect = np.column_stack(np.unravel_index(max_idx, images[0,:,:].shape))\n",
    "np.add.at(\n",
    "    pix_hmap, \n",
    "    (\n",
    "        maxpos_vect[:, 0],\n",
    "        maxpos_vect[:, 1],\n",
    "        maxpos_vect[:, 2]\n",
    "    ),\n",
    "    1\n",
    ")\n",
    "#pix_hmap[maxpos_vect[:, 0], maxpos_vect[:, 1], maxpos_vect[:, 2]] += 1\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_title('Heatmap of highest intensity pixels in dataset')\n",
    "sns.heatmap(pix_hmap.reshape((16,16)), ax=ax, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = images[single_indices].reshape(images[single_indices].shape[0],16,16)\n",
    "\n",
    "# get index of highest energy pixel\n",
    "print(np.unravel_index(np.argmax(imgs[0], axis=None), imgs[0].shape))\n",
    "fix, ax = plt.subplots()\n",
    "ax.imshow(imgs[0])\n",
    "ax.plot(0,0, 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"DATA_PATH\": \"../../data/real/anodedata.txt\",              \n",
    "    \"MODEL_PATH\": \"../../data/output/models/\",                \n",
    "    \"CLASSIFIER\": \"Project-0.97.hdf5\",                      \n",
    "    \"SINGLE_ENERGY_MODEL\": \"single_energy_model_name.hdf5\",    \n",
    "    \"SINGLE_POSITION_MODEL\": \"single_position_model_name.hdf5\",\n",
    "    \"DOUBLE_ENERGY_MODEL\": \"double_energy_model_name.hdf5\",    \n",
    "    \"DOUBLE_POSITION_MODEL\": \"double_position_model_name.hdf5\" \n",
    "}\n",
    "\n",
    "data = import_real_data(config)\n",
    "print(data['image'].type)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
